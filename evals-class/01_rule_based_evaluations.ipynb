{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based evaluation of LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a LLM-based system that we want to evaluate. We can use rule-based evaluation to evaluate the LLM.\n",
    "\n",
    "For example, imagine we have a system that summarises news articles. A simple rule we could follow is to check if the summary contains words that are contained in the original article.\n",
    "\n",
    "For example, suppose we have an article about generative AI:\n",
    "\n",
    " > Policy Lab has experimented with Artificial Intelligence (AI) in policy development with teams across government, and beyond, for a number of years. In 2019 we worked with the Department for Transport’s data science team to consider the role that AI could play in improving the efficiency and effectiveness of the policy consultation process. In 2022 we used AI to create a vision for the future of Hounslow with the local authority. In 2023, we commissioned the creation of the Ecological Intelligence Agency, a speculative artefact to help experience the role AI might have in future decision-making in environmental policy. \n",
    " >\n",
    " >This blog explains how Policy Lab used generative AI in policy relating to the future of the subsurface. Broadly speaking, generative AI can be understood as systems that create new data, which could be new code, text, images, video or other forms of data. We used generative AI to visualise evidence, bring to life policy ideas, and create this blog, written iteratively with a system trained on Policy Lab’s publicly available content. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = (\"Policy Lab has experimented with Artificial Intelligence (AI) in policy development with teams across government, \"\n",
    "           \"and beyond, for a number of years. In 2019 we worked with the Department for Transport’s data science team to consider \"\n",
    "           \"the role that AI could play in improving the efficiency and effectiveness of the policy consultation process. \"\n",
    "           \"In 2022 we used AI to create a vision for the future of Hounslow with the local authority. \"\n",
    "           \"In 2023, we commissioned the creation of the Ecological Intelligence Agency, a speculative artefact to help experience \"\n",
    "           \"the role AI might have in future decision-making in environmental policy. \"\n",
    "           \"\\n\\n\"\n",
    "           \"This blog explains how Policy Lab used generative AI in policy relating to the future of the subsurface. \"\n",
    "           \"Broadly speaking, generative AI can be understood as systems that create new data, which could be new code, text, images, \"\n",
    "           \"video or other forms of data. We used generative AI to visualise evidence, bring to life policy ideas, and create this blog, \"\n",
    "           \"written iteratively with a system trained on Policy Lab’s publicly available content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_1 = \"Give me a short summary of the following article:\"\n",
    "\n",
    "prompt_1 = f\"{instruction_1}\\n\\n{article}\"\n",
    "\n",
    "response_1 = get_response(prompt_1)\n",
    "\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the response contains the expected words\n",
    "\n",
    "We expect the response to contain the following words: *__\"Policy Lab\"__*, *__\"AI\"__*, *__\"generative AI\"__*, *__\"government\"__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_words = [\"Policy Lab\", \"AI\", \"generative AI\", \"government\"]\n",
    "\n",
    "def check_expected_words(response, expected_words):\n",
    "    for word in expected_words:\n",
    "        assert word.lower() in response.lower(), f\"The word {word} is not in the response\"\n",
    "\n",
    "check_expected_words(response_1, expected_words)\n",
    "print(\"All expected words are in the response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we want to make sure the response does not contain lists?\n",
    "\n",
    "Imagine we don't want the response to be short, maximum a couple of sentences with no lists.\n",
    "\n",
    "We need a new prompt and a new evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_2 = (\"Give me a short summary of the following article, \"\n",
    "                \"maximum a couple of sentences with no lists or quotes:\")\n",
    "\n",
    "prompt_2 = f\"{instruction_2}\\n\\n{article}\"\n",
    "\n",
    "response_2 = get_response(prompt_2)\n",
    "\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_expected_words(response_2, expected_words)\n",
    "print(\"All expected words are in the response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_lists_in_response(response):\n",
    "    assert \"1. \" not in response, \"The response contains a list\"\n",
    "\n",
    "no_lists_in_response(response_2)\n",
    "print(\"The response contains no lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_lists_in_response(response_1)\n",
    "print(\"The response contains no lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
