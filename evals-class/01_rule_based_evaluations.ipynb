{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based evaluation of LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a LLM-based system that we want to evaluate. We can use rule-based evaluation to evaluate the LLM.\n",
    "\n",
    "For example, imagine we have a system that summarises news articles. A simple rule we could follow is to check if the summary contains words that are contained in the original article.\n",
    "\n",
    "For example, suppose we have an article about generative AI:\n",
    "\n",
    " > Policy Lab has experimented with Artificial Intelligence (AI) in policy development with teams across government, and beyond, for a number of years. In 2019 we worked with the Department for Transport’s data science team to consider the role that AI could play in improving the efficiency and effectiveness of the policy consultation process. In 2022 we used AI to create a vision for the future of Hounslow with the local authority. In 2023, we commissioned the creation of the Ecological Intelligence Agency, a speculative artefact to help experience the role AI might have in future decision-making in environmental policy. \n",
    " >\n",
    " >This blog explains how Policy Lab used generative AI in policy relating to the future of the subsurface. Broadly speaking, generative AI can be understood as systems that create new data, which could be new code, text, images, video or other forms of data. We used generative AI to visualise evidence, bring to life policy ideas, and create this blog, written iteratively with a system trained on Policy Lab’s publicly available content. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = (\"Policy Lab has experimented with Artificial Intelligence (AI) in policy development with teams across government, \"\n",
    "           \"and beyond, for a number of years. In 2019 we worked with the Department for Transport’s data science team to consider \"\n",
    "           \"the role that AI could play in improving the efficiency and effectiveness of the policy consultation process. \"\n",
    "           \"In 2022 we used AI to create a vision for the future of Hounslow with the local authority. \"\n",
    "           \"In 2023, we commissioned the creation of the Ecological Intelligence Agency, a speculative artefact to help experience \"\n",
    "           \"the role AI might have in future decision-making in environmental policy. \"\n",
    "           \"\\n\\n\"\n",
    "           \"This blog explains how Policy Lab used generative AI in policy relating to the future of the subsurface. \"\n",
    "           \"Broadly speaking, generative AI can be understood as systems that create new data, which could be new code, text, images, \"\n",
    "           \"video or other forms of data. We used generative AI to visualise evidence, bring to life policy ideas, and create this blog, \"\n",
    "           \"written iteratively with a system trained on Policy Lab’s publicly available content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_response\n",
      "File \u001b[0;32m~/hub/ukblogsrag/evals-class/common.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manthropic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Anthropic\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from common import get_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m instruction_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me a short summary of the following article:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m prompt_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstruction_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00marticle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m response_1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m(prompt_1)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_response' is not defined"
     ]
    }
   ],
   "source": [
    "instruction_1 = \"Give me a short summary of the following article:\"\n",
    "\n",
    "prompt_1 = f\"{instruction_1}\\n\\n{article}\"\n",
    "\n",
    "response_1 = get_response(prompt_1)\n",
    "\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the response contains the expected words\n",
    "\n",
    "We expect the response to contain the following words: *__\"Policy Lab\"__*, *__\"AI\"__*, *__\"generative AI\"__*, *__\"government\"__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All expected words are in the response\n"
     ]
    }
   ],
   "source": [
    "expected_words = [\"Policy Lab\", \"AI\", \"generative AI\", \"government\"]\n",
    "\n",
    "def check_expected_words(response, expected_words):\n",
    "    for word in expected_words:\n",
    "        assert word.lower() in response.lower(), f\"The word {word} is not in the response\"\n",
    "\n",
    "check_expected_words(response_1, expected_words)\n",
    "print(\"All expected words are in the response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we want to make sure the response does not contain lists?\n",
    "\n",
    "Imagine we don't want the response to be short, maximum a couple of sentences with no lists.\n",
    "\n",
    "We need a new prompt and a new evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Lab has been exploring the use of Artificial Intelligence in policy development across various government sectors for several years. Their recent work includes using generative AI to visualize evidence, develop policy ideas, and create content related to the future of the subsurface, demonstrating AI's potential to enhance policy-making processes and outcomes.\n"
     ]
    }
   ],
   "source": [
    "instruction_2 = (\"Give me a short summary of the following article, \"\n",
    "                \"maximum a couple of sentences with no lists or quotes:\")\n",
    "\n",
    "prompt_2 = f\"{instruction_2}\\n\\n{article}\"\n",
    "\n",
    "response_2 = get_response(prompt_2)\n",
    "\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All expected words are in the response\n"
     ]
    }
   ],
   "source": [
    "check_expected_words(response_2, expected_words)\n",
    "print(\"All expected words are in the response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response contains no lists\n"
     ]
    }
   ],
   "source": [
    "def no_lists_in_response(response):\n",
    "    assert \"1. \" not in response, \"The response contains a list\"\n",
    "\n",
    "no_lists_in_response(response_2)\n",
    "print(\"The response contains no lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The response contains a list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mno_lists_in_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe response contains no lists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m, in \u001b[0;36mno_lists_in_response\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mno_lists_in_response\u001b[39m(response):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe response contains a list\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The response contains a list"
     ]
    }
   ],
   "source": [
    "no_lists_in_response(response_1)\n",
    "print(\"The response contains no lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
