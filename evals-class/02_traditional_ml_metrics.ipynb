{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we use traditional ML metrics to evaluate our model?\n",
    "\n",
    "Under certain circumstances, such as when we have a labelled dataset and the LLM is used as a classifier, we can use traditional ML metrics to evaluate our model.\n",
    "\n",
    "Imagine we have a dataset with articles and we want to classify them as about *__AI__*, *__music__*, *__food__*, *__education__*, or *__unknown__*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_response\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'article_about_education',\n",
       " 'name': 'Article about education',\n",
       " 'article': 'Ofsted has announced changes to how school inspections are carried out to reduce pressures on teachers and school leaders.\\nOfsted provides independent, up to date evaluations on the quality of education, behaviour, personal development, safeguarding, and leadership, which schools and parents value. \\nWe want the inspection system to be as helpful as possible for everyone, which is why we’ve listened to calls from teachers and school leaders and are working with Ofsted to make improvements to the process. \\nHere we tell you everything you need to know about the changes by Ofsted and why they’re happening.',\n",
       " 'category': 'education'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"test_classification_cases.json\", \"r\") as f:\n",
    "    test_cases = json.load(f)\n",
    "\n",
    "test_cases[\"tests\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI', 'music', 'education', 'food', 'food', 'unknown']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_categories = [test_case[\"category\"] for test_case in test_cases[\"tests\"]]\n",
    "expected_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"Classify the following article into one of the following categories:\n",
    " - AI\n",
    " - music\n",
    " - food\n",
    " - education\n",
    "\n",
    "If the article is not about any of the categories above, classify it as \"unknown\".\n",
    "\n",
    "Provide no explanation, or any other text, just the category.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_categories = []\n",
    "\n",
    "for test_case in test_cases[\"tests\"]:\n",
    "    article = test_case[\"article\"]\n",
    "    full_prompt = f\"{instruction}\\n\\n{article}\"\n",
    "    response = get_response(full_prompt)\n",
    "    classified_categories.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI', 'education', 'education', 'food', 'education', 'unknown']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con estos resultados, podemos calcular accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_score(y_true: list[str], y_pred: list[str]) -> float:\n",
    "    return sum(1 for t, p in zip(y_true, y_pred) if t == p) / len(y_true)\n",
    "\n",
    "accuracy_score(expected_categories, classified_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
