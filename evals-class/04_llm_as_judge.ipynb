{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM as judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also leverage LLMs to evaluate the quality of the generated text, this is a more flexible, powerful and nuanced approach than using rule-based or statistical metrics, and sometimes better than using cosine similarity; it is however, more expensive and requires more time to execute.\n",
    "\n",
    "It is also worth noting that at this point you are also introducing a new source of error, as an LLM will be used to evaluate the quality of the generated text, and it is not always easy to tell if the LLM is being fair or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, imagine we have the following text:\n",
    "\n",
    "> Policy Lab has experimented with Artificial Intelligence (AI) in policy development with teams across government, and beyond, for a number of years. In 2019 we worked with the Department for Transportâ€™s data science team to consider the role that AI could play in improving the efficiency and effectiveness of the policy consultation process. In 2022 we used AI to create a vision for the future of Hounslow with the local authority. In 2023, we commissioned the creation of the Ecological Intelligence Agency, a speculative artefact to help experience the role AI might have in future decision-making in environmental policy. \n",
    "\n",
    "And we have asked the original writer to provide a summary of the text, **This is our golden reference**:\n",
    "\n",
    "> Policy Lab has explored the use of AI in policy development across various government projects, including improving policy consultation processes, envisioning future urban planning, and investigating AI's potential role in environmental policy decision-making.\n",
    "\n",
    "### What we want to evaluate\n",
    "\n",
    "And we have requested different language models to provide a summary of the text using a variety of prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Reference summary\n",
       "Policy Lab has explored the use of AI in policy development across various government projects, including improving policy consultation processes, envisioning future urban planning, and investigating AI's potential role in environmental policy decision-making.\n",
       "\n",
       "## Model 1\n",
       "Policy Lab has explored the application of Artificial Intelligence in diverse government policy initiatives, including enhancing policy consultation, envisioning local community futures, and examining AI's potential role in environmental policy decisions.\n",
       "\n",
       "## Model 2\n",
       "Policy Lab has explored AI applications in governmental policy creation, collaborating with various agencies to enhance consultation procedures, generate urban forecasts, and envision futuristic environmental decision-making tools.\n",
       "\n",
       "## Model 3 (worst)\n",
       "Policy Lab has been using Artificial Intelligence to replace human decision-making in government policy development, creating automated systems to make key decisions without input from policymakers or the public.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reference_summary = \"Policy Lab has explored the use of AI in policy development across various government projects, including improving policy consultation processes, envisioning future urban planning, and investigating AI's potential role in environmental policy decision-making.\"\n",
    "summary_1 = \"Policy Lab has explored the application of Artificial Intelligence in diverse government policy initiatives, including enhancing policy consultation, envisioning local community futures, and examining AI's potential role in environmental policy decisions.\"\n",
    "summary_2 = \"Policy Lab has explored AI applications in governmental policy creation, collaborating with various agencies to enhance consultation procedures, generate urban forecasts, and envision futuristic environmental decision-making tools.\"\n",
    "summary_3 = \"Policy Lab has been using Artificial Intelligence to replace human decision-making in government policy development, creating automated systems to make key decisions without input from policymakers or the public.\"\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "## Reference summary\\n{reference_summary}\\n\n",
    "## Model 1\\n{summary_1}\\n\n",
    "## Model 2\\n{summary_2}\\n\n",
    "## Model 3 (worst)\\n{summary_3}\\n\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our judge\n",
    "\n",
    "As we will be using an LLM, we need to craft a prompt that instructs the language model to evaluate the quality of the generated text.\n",
    "\n",
    "Usually the prompts are asked to evaluate the quality of the generated text based on a given reference, and output a score given a scale, such as 1 to 5 or 1 to 10, however, you can also ask the LLM to output a ranking, or even a more verbose evaluation.\n",
    "\n",
    "For this example, we will ask the LLM to evaluate the quality of the generated text based on a given reference, and output a score between 1 and 10, and as an extra we will also ask the LLM to provide an explanation for its score.\n",
    "\n",
    "To make this evaluation automated, we will also require the LLM to output its score in a specific format, so we can easily parse it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_prompt = \"\"\"\n",
    "You are an expert at evaluating the quality of summaries.\n",
    "You will be given a reference summary and a generated summary.\n",
    "You need to evaluate the quality of the generated summary based on the reference summary, and output a score between 1 and 10.\n",
    "You also need to provide an explanation for your score.\n",
    "You need to output your score and explanation in the following JSON format:\n",
    "\n",
    "{{\"score\": <score>, \"explanation\": <explanation>}}\n",
    "\n",
    "The reference summary is:\n",
    "```\n",
    "{reference_summary}\n",
    "```\n",
    "\n",
    "The generated summary is:\n",
    "```\n",
    "{summary}\n",
    "```\n",
    "\n",
    "Your output should only be the JSON, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert at evaluating the quality of summaries.\n",
      "You will be given a reference summary and a generated summary.\n",
      "You need to evaluate the quality of the generated summary based on the reference summary, and output a score between 1 and 10.\n",
      "You also need to provide an explanation for your score.\n",
      "You need to output your score and explanation in the following JSON format:\n",
      "\n",
      "{\"score\": <score>, \"explanation\": <explanation>}\n",
      "\n",
      "\n",
      "The reference summary is:\n",
      "Policy Lab has explored the use of AI in policy development across various government projects, including improving policy consultation processes, envisioning future urban planning, and investigating AI's potential role in environmental policy decision-making.\n",
      "\n",
      "The generated summary is:\n",
      "Policy Lab has explored the application of Artificial Intelligence in diverse government policy initiatives, including enhancing policy consultation, envisioning local community futures, and examining AI's potential role in environmental policy decisions.\n",
      "\n",
      "Your output should only be the JSON, nothing else.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "summary_1_prompt = judge_prompt.format(reference_summary=reference_summary, summary=summary_1)\n",
    "\n",
    "print(summary_1_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": 9,\n",
      "  \"explanation\": \"The generated summary accurately captures the key points of the reference summary with only minor differences. It correctly mentions Policy Lab's exploration of AI in government projects, including policy consultation improvements and environmental policy decision-making. The main difference is in the phrasing of 'future urban planning' in the reference, which is described as 'envisioning local community futures' in the generated summary. This is a slight shift in focus but still conveys a similar concept. The generated summary maintains the essence and scope of the original while using slightly different wording, demonstrating a high level of accuracy and comprehension.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from common import get_response\n",
    "\n",
    "summary_1_judge_response = get_response(summary_1_prompt)\n",
    "\n",
    "print(summary_1_judge_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": 2,\n",
      "  \"explanation\": \"The generated summary severely misrepresents the content of the reference summary. While the reference indicates that Policy Lab has explored the use of AI in various aspects of policy development, the generated summary incorrectly states that AI is being used to replace human decision-making entirely. The reference mentions AI being used to improve processes and investigate potential roles, not to automate key decisions without human input. The generated summary also omits the specific areas mentioned in the reference (consultation processes, urban planning, environmental policy) and introduces unfounded claims about excluding policymakers and the public. This summary is highly inaccurate and misleading compared to the reference.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from common import get_response\n",
    "\n",
    "summary_3_prompt = judge_prompt.format(reference_summary=reference_summary, summary=summary_3)\n",
    "\n",
    "summary_3_judge_response = get_response(summary_3_prompt)\n",
    "\n",
    "print(summary_3_judge_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
